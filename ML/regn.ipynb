{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1758598528442,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "n7md70PI-iB0",
    "outputId": "e2e78647-f8d6-4226-91f7-62b9d210f7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106,
     "status": "ok",
     "timestamp": 1758591319143,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "8eDew3Av-jLH",
    "outputId": "050e6bd1-0688-4657-9fa7-4b02f83e62a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-09-23 01:35:20--  https://developer.download.nvidia.com/compute/tensorrt/10.13.2/local_installers/nv-tensorrt-local-repo-ubuntu2204-10.13.2-cuda-12.9_1.0-1_amd64.deb\n",
      "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 23.15.241.19, 23.15.241.65\n",
      "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|23.15.241.19|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -c https://developer.download.nvidia.com/compute/tensorrt/10.13.2/local_installers/nv-tensorrt-local-repo-ubuntu2204-10.13.2-cuda-12.9_1.0-1_amd64.deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55258,
     "status": "ok",
     "timestamp": 1758598585835,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "xK5W0yd6AKaj",
    "outputId": "3c5fd42b-d8be-464f-9aca-b4d6a2135f93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 126629 files and directories currently installed.)\n",
      "Preparing to unpack nv-tensorrt-local-repo-ubuntu2204-10.13.2-cuda-12.9_1.0-1_amd64.deb ...\n",
      "Unpacking nv-tensorrt-local-repo-ubuntu2204-10.13.2-cuda-12.9 (1.0-1) over (1.0-1) ...\n",
      "Setting up nv-tensorrt-local-repo-ubuntu2204-10.13.2-cuda-12.9 (1.0-1) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo dpkg -i \"nv-tensorrt-local-repo-ubuntu2204-10.13.2-cuda-12.9_1.0-1_amd64.deb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNu5G_TiCFtG"
   },
   "outputs": [],
   "source": [
    "!sudo cp /var/nv-tensorrt-local-repo-ubuntu2204-10.13.2-cuda-12.9/nv-tensorrt-local-AF54650E-keyring.gpg /usr/share/keyrings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1758597232524,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "u5T6eTRPDrHs",
    "outputId": "aa98fb9b-7793-4a40-dca9-5657174472b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive_uri-https_cloud_r-project_org_bin_linux_ubuntu-jammy.list\n",
      "archive_uri-https_r2u_stat_illinois_edu_ubuntu-jammy.list\n",
      "cuda-ubuntu2204-x86_64.list.disabled\n",
      "deadsnakes-ubuntu-ppa-jammy.list\n",
      "github-cli.list\n",
      "graphics-drivers-ubuntu-ppa-jammy.list\n",
      "nv-tensorrt-local-ubuntu2204-10.13.2-cuda-12.9.list\n",
      "ubuntugis-ubuntu-ppa-jammy.list\n"
     ]
    }
   ],
   "source": [
    "!ls /etc/apt/sources.list.d/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 8400,
     "status": "ok",
     "timestamp": 1758591572596,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "PA5Hvw8FFskF",
    "outputId": "0130b3ae-7dde-4f8d-9619-74f346c297c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libnvinfer10:\n",
      "  Installed: (none)\n",
      "  Candidate: 10.13.3.9-1+cuda13.0\n",
      "  Version table:\n",
      "     10.13.3.9-1+cuda13.0 600\n",
      "        600 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages\n",
      "     10.13.3.9-1+cuda12.9 600\n",
      "        600 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages\n",
      "     10.13.2.6-1+cuda13.0 600\n",
      "        600 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages\n",
      "libnvonnxparsers10:\n",
      "  Installed: (none)\n",
      "  Candidate: 10.13.3.9-1+cuda13.0\n",
      "  Version table:\n",
      "     10.13.3.9-1+cuda13.0 600\n",
      "        600 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages\n",
      "     10.13.3.9-1+cuda12.9 600\n",
      "        600 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages\n",
      "     10.13.2.6-1+cuda13.0 600\n",
      "        600 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages\n",
      "libnvinfer-plugin10:\n",
      "  Installed: (none)\n",
      "  Candidate: 10.13.3.9-1+cuda13.0\n",
      "  Version table:\n",
      "     10.13.3.9-1+cuda13.0 600\n",
      "        600 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages\n",
      "     10.13.3.9-1+cuda12.9 600\n",
      "        600 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages\n",
      "     10.13.2.6-1+cuda13.0 600\n",
      "        600 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages\n",
      "python3-libnvinfer:\n",
      "  Installed: (none)\n",
      "  Candidate: 10.13.3.9-1+cuda13.0\n",
      "  Version table:\n",
      "     10.13.3.9-1+cuda13.0 600\n",
      "        600 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages\n",
      "     10.13.3.9-1+cuda12.9 600\n",
      "        600 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages\n",
      "     10.13.2.6-1+cuda13.0 600\n",
      "        600 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages\n"
     ]
    }
   ],
   "source": [
    "!apt-cache policy libnvinfer10 | head -n 10\n",
    "!apt-cache policy libnvonnxparsers10 | head -n 10\n",
    "!apt-cache policy libnvparsers10 | head -n 10\n",
    "!apt-cache policy libnvinfer-plugin10 | head -n 10\n",
    "!apt-cache policy python3-libnvinfer | head -n 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 91,
     "status": "ok",
     "timestamp": 1758591573599,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "GND68c_VD8iA",
    "outputId": "f4f1dff2-ca68-4d24-c18e-e894b31ff683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deb [signed-by=/usr/share/keyrings/nv-tensorrt-local-AF54650E-keyring.gpg] file:///var/nv-tensorrt-local-repo-ubuntu2204-10.13.2-cuda-12.9 /\n"
     ]
    }
   ],
   "source": [
    "!cat /etc/apt/sources.list.d/nv-tensorrt-local-ubuntu2204-10.13.2-cuda-12.9.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1758599582091,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "vQgRCqc8c8r3",
    "outputId": "3eba36b8-75d0-47a8-c1b1-ddaf5face620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat '/etc/apt/sources.list.d/cuda-ubuntu2204-x86_64.list': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!sudo mv /etc/apt/sources.list.d/cuda-ubuntu2204-x86_64.list \\\n",
    "        /etc/apt/sources.list.d/cuda-ubuntu2204-x86_64.list.disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4949,
     "status": "ok",
     "timestamp": 1758599589389,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "w4mYdy1XFLss",
    "outputId": "feae4d0a-1d58-40a6-de71-620ebf42aee2"
   },
   "outputs": [],
   "source": [
    "# 更新索引\n",
    "!sudo apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3020,
     "status": "ok",
     "timestamp": 1758597619025,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "UOFcm4_vKfPV",
    "outputId": "437dc358-e423-45c3-d8a1-dc7f2cbbab7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "libnvinfer-plugin10 is already the newest version (10.13.2.6-1+cuda12.9).\n",
      "libnvinfer10 is already the newest version (10.13.2.6-1+cuda12.9).\n",
      "libnvonnxparsers10 is already the newest version (10.13.2.6-1+cuda12.9).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# 安装 TensorRT runtime + parser + plugin\n",
    "\n",
    "# !sudo apt-get install -y \\\n",
    "#   libnvinfer10=10.13.3.9-1+cuda12.9 \\\n",
    "#   libnvonnxparsers10=10.13.3.9-1+cuda12.9 \\\n",
    "#   libnvinfer-plugin10=10.13.3.9-1+cuda12.9\n",
    "\n",
    "!sudo apt-get install -y \\\n",
    "  libnvinfer10=10.13.2.6-1+cuda12.9 \\\n",
    "  libnvinfer-plugin10=10.13.2.6-1+cuda12.9 \\\n",
    "  libnvonnxparsers10=10.13.2.6-1+cuda12.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1758597624329,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "ZXUgjhR2Smcz",
    "outputId": "b213819a-94e8-4e72-a4da-0c7ba6650525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/etc/apt/sources.list.d/nv-tensorrt-local-ubuntu2204-10.13.2-cuda-12.9.list:deb [signed-by=/usr/share/keyrings/nv-tensorrt-local-AF54650E-keyring.gpg] file:///var/nv-tensorrt-local-repo-ubuntu2204-10.13.2-cuda-12.9 /\n",
      "/etc/apt/sources.list.d/cuda-ubuntu2204-x86_64.list.disabled:deb [signed-by=/usr/share/keyrings/cuda-archive-keyring.gpg] https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/ /\n"
     ]
    }
   ],
   "source": [
    "!grep -r \"cuda\" /etc/apt/sources.list.d/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1758597949690,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "HtCdXw_XTOE0",
    "outputId": "3a298bbe-378f-4725-c92f-88be0ef7d16b"
   },
   "outputs": [],
   "source": [
    "!ls /var/nv-tensorrt-local-repo-ubuntu2204-10.13.2-cuda-12.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1758597953647,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "XHnx7Ci7Ki6P",
    "outputId": "e20a8a4d-35be-489e-87df-f9544307abdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not get lock /var/lib/dpkg/lock-frontend. It is held by process 12352 (apt-get)\n",
      "N: Be aware that removing the lock file is not a solution and may break your system.\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), is another process using it?\n"
     ]
    }
   ],
   "source": [
    "# 安装开发包\n",
    "# !sudo apt-get install -y \\\n",
    "#   libnvinfer-dev=10.13.3.9-1+cuda12.9 \\\n",
    "#   libnvonnxparsers-dev=10.13.3.9-1+cuda12.9 \\\n",
    "#   libnvinfer-plugin-dev=10.13.3.9-1+cuda12.9\n",
    "\n",
    "!sudo apt-get install -y \\\n",
    "  libnvinfer10=10.13.2.6-1+cuda12.9 \\\n",
    "  libnvinfer-plugin10=10.13.2.6-1+cuda12.9 \\\n",
    "  libnvonnxparsers10=10.13.2.6-1+cuda12.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 41245,
     "status": "error",
     "timestamp": 1758597941662,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "w42BrIYkKjtA",
    "outputId": "f58ec93a-2395-4b42-cb10-fd14149a9844"
   },
   "outputs": [],
   "source": [
    "# 安装 Python 绑定\n",
    "!sudo apt-get install -y \\\n",
    "  python3-libnvinfer=10.13.2.6-1+cuda12.9 \\\n",
    "  python3-libnvinfer-dev=10.13.2.6-1+cuda12.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2621,
     "status": "ok",
     "timestamp": 1758509154052,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "9fzXbwRsKoIp",
    "outputId": "ad648ec7-990b-490f-d179-c892c016bda0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "Some packages could not be installed. This may mean that you have\n",
      "requested an impossible situation or if you are using the unstable\n",
      "distribution that some required packages have not yet been created\n",
      "or been moved out of Incoming.\n",
      "The following information may help to resolve the situation:\n",
      "\n",
      "The following packages have unmet dependencies:\n",
      " tensorrt : Depends: libnvinfer10 (= 10.13.3.9-1+cuda13.0) but 10.13.3.9-1+cuda12.9 is to be installed\n",
      "            Depends: libnvinfer-plugin10 (= 10.13.3.9-1+cuda13.0) but 10.13.3.9-1+cuda12.9 is to be installed\n",
      "            Depends: libnvinfer-vc-plugin10 (= 10.13.3.9-1+cuda13.0) but 10.13.3.9-1+cuda12.9 is to be installed\n",
      "            Depends: libnvinfer-lean10 (= 10.13.3.9-1+cuda13.0) but 10.13.3.9-1+cuda12.9 is to be installed\n",
      "            Depends: libnvinfer-dispatch10 (= 10.13.3.9-1+cuda13.0) but 10.13.3.9-1+cuda12.9 is to be installed\n",
      "            Depends: libnvonnxparsers10 (= 10.13.3.9-1+cuda13.0) but 10.13.3.9-1+cuda12.9 is to be installed\n",
      "            Depends: libnvinfer-bin (= 10.13.3.9-1+cuda13.0) but 10.13.3.9-1+cuda12.9 is to be installed\n",
      "            Depends: libnvinfer-dev (= 10.13.3.9-1+cuda13.0) but 10.13.3.9-1+cuda12.9 is to be installed\n",
      "            Depends: libnvinfer-lean-dev (= 10.13.3.9-1+cuda13.0) but 10.13.3.9-1+cuda12.9 is to be installed\n",
      "            Depends: libnvinfer-plugin-dev (= 10.13.3.9-1+cuda13.0) but 10.13.3.9-1+cuda12.9 is to be installed\n",
      "            Depends: libnvinfer-vc-plugin-dev (= 10.13.3.9-1+cuda13.0) but 10.13.3.9-1+cuda12.9 is to be installed\n",
      "            Depends: libnvinfer-dispatch-dev (= 10.13.3.9-1+cuda13.0) but 10.13.3.9-1+cuda12.9 is to be installed\n",
      "            Depends: libnvonnxparsers-dev (= 10.13.3.9-1+cuda13.0) but 10.13.3.9-1+cuda12.9 is to be installed\n",
      "            Depends: libnvinfer-samples (= 10.13.3.9-1+cuda13.0) but 10.13.3.9-1+cuda12.9 is to be installed\n",
      "            Depends: python3-libnvinfer-dev (= 10.13.3.9-1+cuda13.0) but 10.13.3.9-1+cuda12.9 is to be installed\n",
      "            Depends: libnvinfer-win-builder-resource10 (= 10.13.3.9-1+cuda13.0) but 10.13.3.9-1+cuda12.9 is to be installed\n",
      "            Depends: libnvinfer-headers-python-plugin-dev (= 10.13.3.9-1+cuda13.0) but 10.13.3.9-1+cuda12.9 is to be installed\n",
      "E: Unable to correct problems, you have held broken packages.\n"
     ]
    }
   ],
   "source": [
    "# 安装 metapackage tensorrt（包含 samples 和工具）\n",
    "!sudo apt-get install -y tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hL-DtwdJKqp3"
   },
   "outputs": [],
   "source": [
    "# 防止 apt 自动升级覆盖版本\n",
    "!sudo apt-mark hold \\\n",
    "  libnvinfer10 libnvonnxparsers10 libnvparsers10 libnvinfer-plugin10 \\\n",
    "  libnvinfer-dev libnvonnxparsers-dev libnvparsers-dev libnvinfer-plugin-dev \\\n",
    "  python3-libnvinfer python3-libnvinfer-dev tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgHRL__n9IXp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "project_path = '/content/drive/MyDrive/Colab Notebooks/smartuvm_test'\n",
    "os.chdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1758612711612,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "GPQ7wHlIrAm0",
    "outputId": "6ef502d6-6943-4b06-f8ee-a8bcef8a0268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Yolov7-tracker\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/MyDrive/Yolov7-tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 370,
     "status": "ok",
     "timestamp": 1758503266079,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "hOV_ds0xqQRs",
    "outputId": "08fb6eb3-b3c1-4904-96a9-7595b230ed76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
      "Cuda compilation tools, release 12.5, V12.5.82\n",
      "Build cuda_12.5.r12.5/compiler.34385749_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1758503262444,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "sQkLWmfg9k6e",
    "outputId": "aeedf787-27cb-4521-ec99-e27e686abe33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ubuntu 22.04.4 LTS \\n \\l\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat /etc/issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 119,
     "status": "ok",
     "timestamp": 1758465069539,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "w_Vcb7K_rlmU",
    "outputId": "a098fc39-05c8-48d6-8bd1-ca4630728e72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 21 14:31:10 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   43C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 362,
     "status": "ok",
     "timestamp": 1758500844036,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "tRVXN5H40V77",
    "outputId": "8fc2bc65-c6db-483c-be46-525fadd0d3f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec [TensorRT v101302] [b6] # trtexec\n",
      "=== Model Options ===\n",
      "  --onnx=<file>               ONNX model\n",
      "\n",
      "=== Build Options ===\n",
      "  --minShapes=spec                   Build with dynamic shapes using a profile with the min shapes provided\n",
      "  --optShapes=spec                   Build with dynamic shapes using a profile with the opt shapes provided\n",
      "  --maxShapes=spec                   Build with dynamic shapes using a profile with the max shapes provided\n",
      "  --minShapesCalib=spec              Calibrate with dynamic shapes using a profile with the min shapes provided\n",
      "  --optShapesCalib=spec              Calibrate with dynamic shapes using a profile with the opt shapes provided\n",
      "  --maxShapesCalib=spec              Calibrate with dynamic shapes using a profile with the max shapes provided\n",
      "                                     Note: All three of min, opt and max shapes must be supplied.\n",
      "                                           However, if only opt shapes is supplied then it will be expanded so\n",
      "                                           that min shapes and max shapes are set to the same values as opt shapes.\n",
      "                                           Input names can be wrapped with escaped single quotes (ex: 'Input:0').\n",
      "                                     Example input shapes spec: input0:1x3x256x256,input1:1x3x128x128\n",
      "                                     For scalars (0-D shapes), use input0:scalar or simply input0: with nothing after the colon.\n",
      "                                     Each input shape is supplied as a key-value pair where key is the input name and\n",
      "                                     value is the dimensions (including the batch dimension) to be used for that input.\n",
      "                                     Each key-value pair has the key and value separated using a colon (:).\n",
      "                                     Multiple input shapes can be provided via comma-separated key-value pairs, and each input name can\n",
      "                                     contain at most one wildcard ('*') character.\n",
      "  --inputIOFormats=spec              Type and format of each of the input tensors (default = all inputs in fp32:chw)\n",
      "                                     See --outputIOFormats help for the grammar of type and format list.\n",
      "                                     Note: If this option is specified, please set comma-separated types and formats for all\n",
      "                                           inputs following the same order as network inputs ID (even if only one input\n",
      "                                           needs specifying IO format) or set the type and format once for broadcasting.\n",
      "  --outputIOFormats=spec             Type and format of each of the output tensors (default = all outputs in fp32:chw)\n",
      "                                     Note: If this option is specified, please set comma-separated types and formats for all\n",
      "                                           outputs following the same order as network outputs ID (even if only one output\n",
      "                                           needs specifying IO format) or set the type and format once for broadcasting.\n",
      "                                     IO Formats: spec  ::= IOfmt[\",\"spec]\n",
      "                                                 IOfmt ::= type:fmt\n",
      "                                                 type  ::= \"fp32\"|\"fp16\"|\"bf16\"|\"int32\"|\"int64\"|\"int8\"|\"uint8\"|\"bool\"\n",
      "                                                 fmt   ::= (\"chw\"|\"chw2\"|\"hwc8\"|\"chw4\"|\"chw16\"|\"chw32\"|\"dhwc8\"|\n",
      "                                                            \"cdhw32\"|\"hwc\"|\"dla_linear\"|\"dla_hwc4\"|\"hwc16\"|\"dhwc\")[\"+\"fmt]\n",
      "  --memPoolSize=poolspec             Specify the size constraints of the designated memory pool(s)\n",
      "                                     Supports the following base-2 suffixes: B (Bytes), G (Gibibytes), K (Kibibytes), M (Mebibytes).\n",
      "                                     If none of suffixes is appended, the defualt unit is in MiB.\n",
      "                                     Note: Also accepts decimal sizes, e.g. 0.25M. Will be rounded down to the nearest integer bytes.\n",
      "                                     In particular, for dlaSRAM the bytes will be rounded down to the nearest power of 2.\n",
      "                                     Pool constraint: poolspec ::= poolfmt[\",\"poolspec]\n",
      "                                                      poolfmt ::= pool:size\n",
      "                                                      pool ::= \"workspace\"|\"dlaSRAM\"|\"dlaLocalDRAM\"|\"dlaGlobalDRAM\"|\"tacticSharedMem\"\n",
      "  --profilingVerbosity=mode          Specify profiling verbosity. mode ::= layer_names_only|detailed|none (default = layer_names_only).\n",
      "                                     Please only assign once.\n",
      "  --avgTiming=M                      Set the number of times averaged in each iteration for kernel selection (default = 8)\n",
      "  --refit                            Mark the engine as refittable. This will allow the inspection of refittable layers \n",
      "                                     and weights within the engine.\n",
      "  --stripWeights                     Strip weights from plan. This flag works with either refit or refit with identical weights. Default\n",
      "                                     to latter, but you can switch to the former by enabling both --stripWeights and --refit at the same\n",
      "                                     time.\n",
      "  --stripAllWeights                  Alias for combining the --refit and --stripWeights options. It marks all weights as refittable,\n",
      "                                     disregarding any performance impact. Additionally, it strips all refittable weights after the \n",
      "                                     engine is built.\n",
      "  --weightless                       [Deprecated] this knob has been deprecated. Please use --stripWeights\n",
      "  --versionCompatible, --vc          Mark the engine as version compatible. This allows the engine to be used with newer versions\n",
      "                                     of TensorRT on the same host OS, as well as TensorRT's dispatch and lean runtimes.\n",
      "  --pluginInstanceNorm, --pi         Set `kNATIVE_INSTANCENORM` to false in the ONNX parser. This will cause the ONNX parser to use\n",
      "                                     a plugin InstanceNorm implementation over the native implementation when parsing.\n",
      "  --uint8AsymmetricQuantizationDLA   Set `kENABLE_UINT8_AND_ASYMMETRIC_QUANTIZATION_DLA` to true in the ONNX parser. This directs the\n",
      "                                     onnx parser to allow UINT8 as a quantization data type and import zero point values directly\n",
      "                                     without converting to float type or all-zero values. Should only be set with DLA software version\n",
      "                                     >= 3.16.\n",
      "  --useRuntime=runtime               TensorRT runtime to execute engine. \"lean\" and \"dispatch\" require loading VC engine and do\n",
      "                                     not support building an engine.\n",
      "                                         runtime::= \"full\"|\"lean\"|\"dispatch\"\n",
      "  --leanDLLPath=<file>               External lean runtime DLL to use in version compatiable mode.\n",
      "  --excludeLeanRuntime               When --versionCompatible is enabled, this flag indicates that the generated engine should\n",
      "                                     not include an embedded lean runtime. If this is set, the user must explicitly specify a\n",
      "                                     valid lean runtime to use when loading the engine.\n",
      "  --monitorMemory                    Enable memory monitor report for debugging usage. (default = disabled)\n",
      "  --sparsity=spec                    Control sparsity (default = disabled). \n",
      "                                     Sparsity: spec ::= \"disable\", \"enable\", \"force\"\n",
      "                                     Note: Description about each of these options is as below\n",
      "                                           disable = do not enable sparse tactics in the builder (this is the default)\n",
      "                                           enable  = enable sparse tactics in the builder (but these tactics will only be\n",
      "                                                     considered if the weights have the right sparsity pattern)\n",
      "                                           force   = enable sparse tactics in the builder and force-overwrite the weights to have\n",
      "                                                     a sparsity pattern (even if you loaded a model yourself)\n",
      "                                                     [Deprecated] this knob has been deprecated.\n",
      "                                                     Please use <polygraphy surgeon prune> to rewrite the weights.\n",
      "  --noTF32                           Disable tf32 precision (default is to enable tf32, in addition to fp32)\n",
      "  --fp16                             Enable fp16 precision, in addition to fp32 (default = disabled)\n",
      "  --bf16                             Enable bf16 precision, in addition to fp32 (default = disabled)\n",
      "  --int8                             Enable int8 precision, in addition to fp32 (default = disabled)\n",
      "  --fp8                              Enable fp8 precision, in addition to fp32 (default = disabled)\n",
      "  --int4                             Enable int4 precision, in addition to fp32 (default = disabled)\n",
      "  --best                             Enable all precisions to achieve the best performance (default = disabled)\n",
      "  --stronglyTyped                    Create a strongly typed network. (default = disabled)\n",
      "  --directIO                         [Deprecated] Avoid reformatting at network boundaries. (default = disabled)\n",
      "  --precisionConstraints=spec        Control precision constraint setting. (default = none)\n",
      "                                     Precision Constraints: spec ::= \"none\" | \"obey\" | \"prefer\"\n",
      "                                         none = no constraints\n",
      "                                         prefer = meet precision constraints set by --layerPrecisions/--layerOutputTypes if possible\n",
      "                                         obey = meet precision constraints set by --layerPrecisions/--layerOutputTypes or fail\n",
      "                                                otherwise\n",
      "  --layerPrecisions=spec             Control per-layer precision constraints. Effective only when precisionConstraints is set to\n",
      "                                     \"obey\" or \"prefer\". (default = none)\n",
      "                                     The specs are read left-to-right, and later ones override earlier ones. Each layer name can\n",
      "                                     contain at most one wildcard ('*') character.\n",
      "                                     Per-layer precision spec ::= layerPrecision[\",\"spec]\n",
      "                                                         layerPrecision ::= layerName\":\"precision\n",
      "                                                         precision ::= \"fp32\"|\"fp16\"|\"bf16\"|\"int32\"|\"int8\"\n",
      "  --layerOutputTypes=spec            Control per-layer output type constraints. Effective only when precisionConstraints is set to\n",
      "                                     \"obey\" or \"prefer\". (default = none\n",
      "                                     The specs are read left-to-right, and later ones override earlier ones. Each layer name can\n",
      "                                     contain at most one wildcard ('*') character. If a layer has more than\n",
      "                                     one output, then multiple types separated by \"+\" can be provided for this layer.\n",
      "                                     Per-layer output type spec ::= layerOutputTypes[\",\"spec]\n",
      "                                                           layerOutputTypes ::= layerName\":\"type\n",
      "                                                           type ::= \"fp32\"|\"fp16\"|\"bf16\"|\"int32\"|\"int8\"[\"+\"type]\n",
      "  --layerDeviceTypes=spec            Specify layer-specific device type.\n",
      "                                     The specs are read left-to-right, and later ones override earlier ones. If a layer does not have\n",
      "                                     a device type specified, the layer will opt for the default device type.\n",
      "                                     Per-layer device type spec ::= layerDeviceTypePair[\",\"spec]\n",
      "                                                           layerDeviceTypePair ::= layerName\":\"deviceType\n",
      "                                                           deviceType ::= \"GPU\"|\"DLA\"\n",
      "  --calib=<file>                     Read INT8 calibration cache file\n",
      "  --safe                             Enable build safety certified engine, if DLA is enable, --buildDLAStandalone will be specified\n",
      "                                     automatically (default = disabled)\n",
      "  --dumpKernelText                   Dump the kernel text to a file, only available when --safe is enabled\n",
      "  --buildDLAStandalone               Enable build DLA standalone loadable which can be loaded by cuDLA, when this option is enabled, \n",
      "                                     --allowGPUFallback is disallowed and --skipInference is enabled by default. Additionally, \n",
      "                                     specifying --inputIOFormats and --outputIOFormats restricts I/O data type and memory layout\n",
      "                                     (default = disabled)\n",
      "  --allowGPUFallback                 When DLA is enabled, allow GPU fallback for unsupported layers (default = disabled)\n",
      "  --consistency                      Perform consistency checking on safety certified engine\n",
      "  --restricted                       Enable safety scope checking with kSAFETY_SCOPE build flag\n",
      "  --saveEngine=<file>                Save the serialized engine\n",
      "  --loadEngine=<file>                Load a serialized engine\n",
      "  --asyncFileReader                  Load a serialized engine using async stream reader. Should be combined with --loadEngine.\n",
      "  --getPlanVersionOnly               Print TensorRT version when loaded plan was created. Works without deserialization of the plan.\n",
      "                                     Use together with --loadEngine. Supported only for engines created with 8.6 and forward.\n",
      "  --tacticSources=tactics            Specify the tactics to be used by adding (+) or removing (-) tactics from the default \n",
      "                                     tactic sources (default = all available tactics).\n",
      "                                     Note: Currently only cuDNN, cuBLAS, cuBLAS-LT, and edge mask convolutions are listed as optional\n",
      "                                           tactics.\n",
      "                                     Tactic Sources: tactics ::= tactic[\",\"tactics]\n",
      "                                                     tactic  ::= (+|-)lib\n",
      "                                                     lib     ::= \"CUBLAS\"|\"CUBLAS_LT\"|\"CUDNN\"|\"EDGE_MASK_CONVOLUTIONS\"\n",
      "                                                                 |\"JIT_CONVOLUTIONS\"\n",
      "                                     For example, to disable cudnn and enable cublas: --tacticSources=-CUDNN,+CUBLAS\n",
      "  --noBuilderCache                   Disable timing cache in builder (default is to enable timing cache)\n",
      "  --noCompilationCache               Disable Compilation cache in builder, and the cache is part of timing cache (default is to enable compilation cache)\n",
      "  --errorOnTimingCacheMiss           Emit error when a tactic being timed is not present in the timing cache (default = false)\n",
      "  --timingCacheFile=<file>           Save/load the serialized global timing cache\n",
      "  --preview=features                 Specify preview feature to be used by adding (+) or removing (-) preview features from the default\n",
      "                                     Preview Features: features ::= feature[\",\"features]\n",
      "                                                       feature  ::= (+|-)flag\n",
      "                                                       flag     ::= \"aliasedPluginIO1003\"\n",
      "                                                                    |\"runtimeActivationResize\"\n",
      "                                                                    |\"profileSharing0806\"\n",
      "  --builderOptimizationLevel         Set the builder optimization level. (default is 3)\n",
      "                                     A Higher level allows TensorRT to spend more time searching for better optimization strategy.\n",
      "                                     Valid values include integers from 0 to the maximum optimization level, which is currently 5.\n",
      "  --maxTactics                       Set the maximum number of tactics to time when there is a choice of tactics. (default is -1)\n",
      "                                     Larger number of tactics allow TensorRT to spend more building time on evaluating tactics.\n",
      "                                     Default value -1 means TensorRT can decide the number of tactics based on its own heuristic.\n",
      "  --hardwareCompatibilityLevel=mode  Make the engine file compatible with other GPU architectures. (default = none)\n",
      "                                     Hardware Compatibility Level: mode ::= \"none\" | \"ampere+\" | \"sameComputeCapability\"\n",
      "                                         none = no compatibility\n",
      "                                         ampere+ = compatible with Ampere and newer GPUs\n",
      "                                         sameComputeCapability = compatible with GPUs that have the same Compute Capability version\n",
      "  --runtimePlatform=platform         Set the target platform for runtime execution. (default = SameAsBuild)\n",
      "                                     When this option is enabled, --skipInference is enabled by default.\n",
      "                                     RuntimePlatfrom: platform ::= \"SameAsBuild\" | \"WindowsAMD64\"\n",
      "                                         SameAsBuild = no requirement for cross-platform compatibility.\n",
      "                                         WindowsAMD64 = set the target platform for engine execution as Windows AMD64 system\n",
      "  --tempdir=<dir>                    Overrides the default temporary directory TensorRT will use when creating temporary files.\n",
      "                                     See IRuntime::setTemporaryDirectory API documentation for more information.\n",
      "  --tempfileControls=controls        Controls what TensorRT is allowed to use when creating temporary executable files.\n",
      "                                     Should be a comma-separated list with entries in the format (in_memory|temporary):(allow|deny).\n",
      "                                     in_memory: Controls whether TensorRT is allowed to create temporary in-memory executable files.\n",
      "                                     temporary: Controls whether TensorRT is allowed to create temporary executable files in the\n",
      "                                                filesystem (in the directory given by --tempdir).\n",
      "                                     For example, to allow in-memory files and disallow temporary files:\n",
      "                                         --tempfileControls=in_memory:allow,temporary:deny\n",
      "                                     If a flag is unspecified, the default behavior is \"allow\".\n",
      "  --maxAuxStreams=N                  Set maximum number of auxiliary streams per inference stream that TRT is allowed to use to run \n",
      "                                     kernels in parallel if the network contains ops that can run in parallel, with the cost of more \n",
      "                                     memory usage. Set this to 0 for optimal memory usage. (default = using heuristics)\n",
      "  --profile                          Build with dynamic shapes using a profile with the min/max/opt shapes provided. Can be specified\n",
      "                                         multiple times to create multiple profiles with contiguous index.\n",
      "                                     (ex: --profile=0 --minShapes=<spec> --optShapes=<spec> --maxShapes=<spec> --profile=1 ...)\n",
      "  --calibProfile                     Select the optimization profile to calibrate by index. (default = 0)\n",
      "  --allowWeightStreaming             Enable a weight streaming engine. Must be specified with --stronglyTyped. TensorRT will disable\n",
      "                                     weight streaming at runtime unless --weightStreamingBudget is specified.\n",
      "  --markDebug                        Specify list of names of tensors to be marked as debug tensors. Separate names with a comma\n",
      "  --markUnfusedTensorsAsDebugTensors Mark unfused tensors as debug tensors\n",
      "  --tilingOptimizationLevel          Set the tiling optimization level. (default is 0)\n",
      "                                     A Higher level allows TensorRT to spend more time searching for better optimization strategy.\n",
      "                                     Valid values include integers from 0 to the maximum tiling optimization level(3).\n",
      "  --l2LimitForTiling                 Set the L2 cache usage limit for tiling optimization(default is -1)\n",
      "  --remoteAutoTuningConfig           Set the remote auto tuning config. Must be specified with --safe.\n",
      "                                     Format: protocol://username[:password]@hostname[:port]?param1=value1&param2=value2\n",
      "                                     Example: ssh://user:pass@192.0.2.100:22?remote_exec_path=/opt/tensorrt/bin&remote_lib_path=/opt/tensorrt/lib\n",
      "\n",
      "=== Inference Options ===\n",
      "  --shapes=spec               Set input shapes for dynamic shapes inference inputs.\n",
      "                              Note: Input names can be wrapped with escaped single quotes (ex: 'Input:0').\n",
      "                              Example input shapes spec: input0:1x3x256x256, input1:1x3x128x128\n",
      "                              For scalars (0-D shapes), use input0:scalar or simply input0: with nothing after the colon.\n",
      "                              Each input shape is supplied as a key-value pair where key is the input name and\n",
      "                              value is the dimensions (including the batch dimension) to be used for that input.\n",
      "                              Each key-value pair has the key and value separated using a colon (:).\n",
      "                              Multiple input shapes can be provided via comma-separated key-value pairs, and each input \n",
      "                              name can contain at most one wildcard ('*') character.\n",
      "  --loadInputs=spec           Load input values from files (default = generate random inputs). Input names can be wrapped with single quotes (ex: 'Input:0')\n",
      "                              Input values spec ::= Ival[\",\"spec]\n",
      "                                           Ival ::= name\":\"file\n",
      "                              Consult the README for more information on generating files for custom inputs.\n",
      "  --iterations=N              Run at least N inference iterations (default = 10)\n",
      "  --warmUp=N                  Run for N milliseconds to warmup before measuring performance (default = 200)\n",
      "  --duration=N                Run performance measurements for at least N seconds wallclock time (default = 3)\n",
      "                              If -1 is specified, inference will keep running unless stopped manually\n",
      "  --sleepTime=N               Delay inference start with a gap of N milliseconds between launch and compute (default = 0)\n",
      "  --idleTime=N                Sleep N milliseconds between two continuous iterations(default = 0)\n",
      "  --infStreams=N              Instantiate N execution contexts to run inference concurrently (default = 1)\n",
      "  --exposeDMA                 Serialize DMA transfers to and from device (default = disabled).\n",
      "  --noDataTransfers           Disable DMA transfers to and from device (default = enabled). Note some device-to-host\n",
      "                              data transfers will remain if output dumping is enabled via the --dumpOutput or\n",
      "                              --exportOutput flags.\n",
      "  --useManagedMemory          Use managed memory instead of separate host and device allocations (default = disabled).\n",
      "  --useSpinWait               Actively synchronize on GPU events. This option may decrease synchronization time but increase CPU usage and power (default = disabled)\n",
      "  --threads                   Enable multithreading to drive engines with independent threads or speed up refitting (default = disabled) \n",
      "  --useCudaGraph              Use CUDA graph to capture engine execution and then launch inference (default = disabled).\n",
      "                              This flag may be ignored if the graph capture fails.\n",
      "  --timeDeserialize           Time the amount of time it takes to deserialize the network and exit.\n",
      "  --timeRefit                 Time the amount of time it takes to refit the engine before inference.\n",
      "  --separateProfileRun        Do not attach the profiler in the benchmark run; if profiling is enabled, a second profile run will be executed (default = disabled)\n",
      "  --skipInference             Exit after the engine has been built and skip inference perf measurement (default = disabled)\n",
      "  --persistentCacheRatio      Set the persistentCacheLimit in ratio, 0.5 represent half of max persistent L2 size (default = 0)\n",
      "  --useProfile                Set the optimization profile for the inference context (default = 0 ).\n",
      "  --allocationStrategy=spec   Specify how the internal device memory for inference is allocated.\n",
      "                              Strategy: spec ::= \"static\"|\"profile\"|\"runtime\"\n",
      "                                  static = Allocate device memory based on max size across all profiles.\n",
      "                                  profile = Allocate device memory based on max size of the current profile.\n",
      "                                  runtime = Allocate device memory based on the actual input shapes.\n",
      "  --saveDebugTensors          Specify list of names of tensors to turn on the debug state\n",
      "                              and filename to save raw outputs to.\n",
      "                              These tensors must be specified as debug tensors during build time.\n",
      "                              Input values spec ::= Ival[\",\"spec]\n",
      "                                           Ival ::= name\":\"file\n",
      "  --saveAllDebugTensors       Save all debug tensors to files. \n",
      "                              Including debug tensors marked by --markDebug and --markUnfusedTensorsAsDebugTensors\n",
      "                              Multiple file formats can be saved simultaneously.\n",
      "                              Input values spec   ::= format[\",\"format]\n",
      "                                           format ::= \"summary\"|\"numpy\"|\"string\"|\"raw\"\n",
      "  --weightStreamingBudget     Set the maximum amount of GPU memory TensorRT is allowed to use for weights.\n",
      "                              It can take on the following values:\n",
      "                                  -2: (default) Disable weight streaming at runtime.\n",
      "                                  -1: TensorRT will automatically decide the budget.\n",
      "                                   0-100%: Percentage of streamable weights that reside on the GPU.\n",
      "                                           0% saves the most memory but will have the worst performance.\n",
      "                                           Requires the '%' character.\n",
      "                                  >=0B: The exact amount of streamable weights that reside on the GPU. Supports the \n",
      "                                       following base-2 suffixes: B (Bytes), G (Gibibytes), K (Kibibytes), M (Mebibytes).\n",
      "\n",
      "=== Reporting Options ===\n",
      "  --verbose                   Use verbose logging (default = false)\n",
      "  --avgRuns=N                 Report performance measurements averaged over N consecutive iterations (default = 10)\n",
      "  --percentile=P1,P2,P3,...   Report performance for the P1,P2,P3,... percentages (0<=P_i<=100, 0 representing max perf, and 100 representing min perf; (default = 90,95,99%)\n",
      "  --dumpRefit                 Print the refittable layers and weights from a refittable engine\n",
      "  --dumpOutput                Print the output tensor(s) of the last inference iteration (default = disabled)\n",
      "  --dumpRawBindingsToFile     Print the input/output tensor(s) of the last inference iteration to file(default = disabled)\n",
      "  --dumpProfile               Print profile information per layer (default = disabled)\n",
      "  --dumpLayerInfo             Print layer information of the engine to console (default = disabled)\n",
      "  --dumpOptimizationProfile   Print the optimization profile(s) information (default = disabled)\n",
      "  --exportTimes=<file>        Write the timing results in a json file (default = disabled)\n",
      "  --exportOutput=<file>       Write the output tensors to a json file (default = disabled)\n",
      "  --exportProfile=<file>      Write the profile information per layer in a json file (default = disabled)\n",
      "  --exportLayerInfo=<file>    Write the layer information of the engine in a json file (default = disabled)\n",
      "\n",
      "=== System Options ===\n",
      "  --device=N                  Select cuda device N (default = 0)\n",
      "  --useDLACore=N              Select DLA core N for layers that support DLA (default = none)\n",
      "  --staticPlugins             Plugin library (.so) to load statically (can be specified multiple times)\n",
      "  --dynamicPlugins            Plugin library (.so) to load dynamically and may be serialized with the engine if they are included in --setPluginsToSerialize (can be specified multiple times)\n",
      "  --setPluginsToSerialize     Plugin library (.so) to be serialized with the engine (can be specified multiple times)\n",
      "  --ignoreParsedPluginLibs    By default, when building a version-compatible engine, plugin libraries specified by the ONNX parser \n",
      "                              are implicitly serialized with the engine (unless --excludeLeanRuntime is specified) and loaded dynamically. \n",
      "                              Enable this flag to ignore these plugin libraries instead.\n",
      "  --safetyPlugins             Plugin library (.so) for TensorRT auto safety to manually load safety plugins specified by the command line arguments.\n",
      "                              Example: --safetyPlugins=/path/to/plugin_lib.so[pluginNamespace1::plugin1,pluginNamespace2::plugin2].\n",
      "                              The option can be specified multiple times with different plugin libraries.\n",
      "\n",
      "=== Help ===\n",
      "  --help, -h                  Print this message\n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v101302] [b6] # trtexec\n"
     ]
    }
   ],
   "source": [
    "!trtexec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13335,
     "status": "ok",
     "timestamp": 1758613821760,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "e9UR3BjiquQw",
    "outputId": "71077023-ff03-4e69-ecb9-63e74d9f84c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/My Drive/Yolov7-tracker/tracker/track.py\", line 23, in <module>\n",
      "    from trackers.byte_tracker import ByteTracker\n",
      "  File \"/content/drive/My Drive/Yolov7-tracker/tracker/trackers/byte_tracker.py\", line 14, in <module>\n",
      "    from .reid_models.engine import load_reid_model, crop_and_resize\n",
      "  File \"/content/drive/My Drive/Yolov7-tracker/tracker/trackers/reid_models/engine.py\", line 25, in <module>\n",
      "    from accelerations.tensorrt_tools import TensorRTConverter, TensorRTInference\n",
      "  File \"/content/drive/My Drive/Yolov7-tracker/tracker/accelerations/tensorrt_tools.py\", line 10, in <module>\n",
      "    import pycuda.driver as cuda\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pycuda/driver.py\", line 70, in <module>\n",
      "    from pycuda._driver import *  # noqa\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ImportError: libcuda.so.1: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python tracker/track.py --dataset smartuvm --detector yolov11_ultra --tracker deepsort --kalman_format byte --detector_model_path /content/drive/MyDrive/train4/weights/best.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 99460,
     "status": "ok",
     "timestamp": 1758196874205,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "1wQdUwoKq8TP",
    "outputId": "cca15eb8-4964-4bd7-e301-d9ab5af72482"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already on 'v2.1'\n",
      "Your branch is up to date with 'origin/v2.1'.\n"
     ]
    }
   ],
   "source": [
    "!git checkout v2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101387,
     "status": "ok",
     "timestamp": 1758613208080,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "0QfppyQOgluG",
    "outputId": "58be91d2-c0eb-44ed-cd5b-7a59474c5413"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorrt\n",
      "  Downloading tensorrt-10.13.3.9.tar.gz (40 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting tensorrt_cu13==10.13.3.9 (from tensorrt)\n",
      "  Downloading tensorrt_cu13-10.13.3.9.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting tensorrt_cu13_libs==10.13.3.9 (from tensorrt_cu13==10.13.3.9->tensorrt)\n",
      "  Downloading tensorrt_cu13_libs-10.13.3.9.tar.gz (706 bytes)\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting tensorrt_cu13_bindings==10.13.3.9 (from tensorrt_cu13==10.13.3.9->tensorrt)\n",
      "  Downloading tensorrt_cu13_bindings-10.13.3.9-cp312-none-manylinux_2_28_x86_64.whl.metadata (606 bytes)\n",
      "Collecting nvidia-cuda-runtime-cu13 (from tensorrt_cu13_libs==10.13.3.9->tensorrt_cu13==10.13.3.9->tensorrt)\n",
      "  Downloading nvidia_cuda_runtime_cu13-0.0.0a0-py2.py3-none-any.whl.metadata (225 bytes)\n",
      "Downloading tensorrt_cu13_bindings-10.13.3.9-cp312-none-manylinux_2_28_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu13-0.0.0a0-py2.py3-none-any.whl (1.2 kB)\n",
      "Building wheels for collected packages: tensorrt, tensorrt_cu13, tensorrt_cu13_libs\n",
      "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for tensorrt: filename=tensorrt-10.13.3.9-py2.py3-none-any.whl size=46401 sha256=a292d7060b09cb9606d50a09f5a59b7e35aee1e175f9834700c9630314551523\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/aa/b0/561559321c1659e43c5a6661986c3072f9c383efeeaaffb1a5\n",
      "  Building wheel for tensorrt_cu13 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for tensorrt_cu13: filename=tensorrt_cu13-10.13.3.9-py2.py3-none-any.whl size=17436 sha256=fafbb09e6bbb5c19063416df620123a3105acc27911d41170aa4ac3c3b28626f\n",
      "  Stored in directory: /root/.cache/pip/wheels/df/4a/b2/ebfc5437a397c53faff0dca4a36c096d4b7d2b7436a2707e60\n",
      "  Building wheel for tensorrt_cu13_libs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for tensorrt_cu13_libs: filename=tensorrt_cu13_libs-10.13.3.9-py2.py3-none-manylinux_2_28_x86_64.whl size=2740897716 sha256=19a54f2106f7d9496433a01a596fa4e363f58901110306abe1ce7b6e9617c6a7\n",
      "  Stored in directory: /root/.cache/pip/wheels/90/c2/ab/e79d384901e98797feb52a9ef4e0bbff65c0732f313bfa604f\n",
      "Successfully built tensorrt tensorrt_cu13 tensorrt_cu13_libs\n",
      "Installing collected packages: tensorrt_cu13_bindings, nvidia-cuda-runtime-cu13, tensorrt_cu13_libs, tensorrt_cu13, tensorrt\n",
      "Successfully installed nvidia-cuda-runtime-cu13-0.0.0a0 tensorrt-10.13.3.9 tensorrt_cu13-10.13.3.9 tensorrt_cu13_bindings-10.13.3.9 tensorrt_cu13_libs-10.13.3.9\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 174069,
     "status": "ok",
     "timestamp": 1758613442009,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "C3RzuHcGhKwJ",
    "outputId": "e9c0ae76-891a-446b-c55b-dd0775032b44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycuda\n",
      "  Downloading pycuda-2025.1.2.tar.gz (1.7 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.7 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting pytools>=2011.2 (from pycuda)\n",
      "  Downloading pytools-2025.2.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from pycuda) (4.4.0)\n",
      "Requirement already satisfied: mako in /usr/local/lib/python3.12/dist-packages (from pycuda) (1.3.10)\n",
      "Collecting siphash24>=1.6 (from pytools>=2011.2->pycuda)\n",
      "  Downloading siphash24-1.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from pytools>=2011.2->pycuda) (4.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from mako->pycuda) (3.0.2)\n",
      "Downloading pytools-2025.2.4-py3-none-any.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.4/99.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading siphash24-1.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
      "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pycuda: filename=pycuda-2025.1.2-cp312-cp312-linux_x86_64.whl size=659050 sha256=3d00460a48b04f1199846e0a5d919c354a0f35ad4b60098abcd9af59a5613682\n",
      "  Stored in directory: /root/.cache/pip/wheels/d5/36/f3/ac5f09d768cad3fa15d5a3449bdfe65c3de58e69d036c73228\n",
      "Successfully built pycuda\n",
      "Installing collected packages: siphash24, pytools, pycuda\n",
      "Successfully installed pycuda-2025.1.2 pytools-2025.2.4 siphash24-1.8\n"
     ]
    }
   ],
   "source": [
    "!pip install pycuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 15140,
     "status": "ok",
     "timestamp": 1758612757482,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "kil_NA4PrHwp",
    "outputId": "7dae8c7b-29ac-4d66-d4bf-5932461b4c44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.0.2)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (3.0.12)\n",
      "Collecting loguru (from -r requirements.txt (line 3))\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting motmetrics==1.4.0 (from -r requirements.txt (line 4))\n",
      "  Downloading motmetrics-1.4.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting ninja (from -r requirements.txt (line 5))\n",
      "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (4.12.0.88)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (2.2.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (11.3.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (1.16.2)\n",
      "Collecting filterpy (from -r requirements.txt (line 15))\n",
      "  Downloading filterpy-1.4.5.zip (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (0.13.2)\n",
      "Collecting thop (from -r requirements.txt (line 18))\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 19)) (2.19.0)\n",
      "Collecting lap (from -r requirements.txt (line 20))\n",
      "  Downloading lap-0.5.12-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (0.9.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 22)) (4.67.1)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 24)) (0.21.4)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 26)) (5.2.0)\n",
      "Collecting ultralytics (from -r requirements.txt (line 28))\n",
      "  Downloading ultralytics-8.3.203-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting xmltodict>=0.12.0 (from motmetrics==1.4.0->-r requirements.txt (line 4))\n",
      "  Downloading xmltodict-1.0.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 8)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 8)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 8)) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 13)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 13)) (3.6.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from filterpy->-r requirements.txt (line 15)) (3.10.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from thop->-r requirements.txt (line 18)) (2.8.0+cu126)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 19)) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 19)) (1.75.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 19)) (3.9)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 19)) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 19)) (5.29.5)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 19)) (75.2.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 19)) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 19)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 19)) (3.1.3)\n",
      "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 24)) (8.2.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 24)) (3.1.45)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 24)) (4.4.0)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 24)) (2.11.9)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 24)) (2.32.4)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 24)) (2.38.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 24)) (4.15.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown->-r requirements.txt (line 26)) (4.13.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown->-r requirements.txt (line 26)) (3.19.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 28)) (0.23.0+cu126)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 28)) (5.9.5)\n",
      "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics->-r requirements.txt (line 28)) (1.25.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics->-r requirements.txt (line 28))\n",
      "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 24)) (4.0.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy->-r requirements.txt (line 15)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy->-r requirements.txt (line 15)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy->-r requirements.txt (line 15)) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy->-r requirements.txt (line 15)) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy->-r requirements.txt (line 15)) (3.2.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 24)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 24)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 24)) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 24)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 24)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 24)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 24)) (2025.8.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop->-r requirements.txt (line 18)) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 19)) (3.0.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 26)) (2.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 26)) (1.7.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 24)) (5.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->thop->-r requirements.txt (line 18)) (1.3.0)\n",
      "Downloading motmetrics-1.4.0-py3-none-any.whl (161 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.5/161.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Downloading lap-0.5.12-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics-8.3.203-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
      "Downloading xmltodict-1.0.2-py3-none-any.whl (13 kB)\n",
      "Building wheels for collected packages: filterpy\n",
      "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110460 sha256=ae12f7dacb1691c8b949fb1ba5bc03f6b8ebf0539cd847572494c88be4fcee98\n",
      "  Stored in directory: /root/.cache/pip/wheels/77/bf/4c/b0c3f4798a0166668752312a67118b27a3cd341e13ac0ae6ee\n",
      "Successfully built filterpy\n",
      "Installing collected packages: xmltodict, ninja, loguru, lap, motmetrics, filterpy, ultralytics-thop, thop, ultralytics\n",
      "Successfully installed filterpy-1.4.5 lap-0.5.12 loguru-0.7.3 motmetrics-1.4.0 ninja-1.13.0 thop-0.1.1.post2209072238 ultralytics-8.3.203 ultralytics-thop-2.0.17 xmltodict-1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 6750,
     "status": "ok",
     "timestamp": 1758612764236,
     "user": {
      "displayName": "Kesh Shank",
      "userId": "04552698536673975213"
     },
     "user_tz": -480
    },
    "id": "QxIXXt9vrR2t",
    "outputId": "98f90a90-39e4-4033-a0b8-5f16daaf8441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.203)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.17)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install ultralytics"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMjoUq6QighktrLSO9RnQVW",
   "gpuType": "T4",
   "mount_file_id": "1XzCefmxXxN-3VauMyl-AnCDIbClkvSk0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
